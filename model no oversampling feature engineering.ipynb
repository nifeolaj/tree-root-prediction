{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abea338",
   "metadata": {},
   "source": [
    "# Importing Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8089c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data handling\n",
    "import numpy as np  # For numerical operations\n",
    "import networkx as nx  # For graph algorithms\n",
    "import ast  # To safely parse edge list strings into Python lists\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import seaborn as sns  # For advanced plots\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV  # Grouped cross-validation and hyperparameter tuning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import community as community_louvain\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab98a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load datasets\n",
    "train_df = pd.read_csv('train.csv')  # Load training data\n",
    "test_df = pd.read_csv('test.csv')  # Load test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb890b3",
   "metadata": {},
   "source": [
    "# Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13de4e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language  sentence   n                                           edgelist  \\\n",
      "0  Japanese         2  23  [(6, 4), (2, 6), (2, 23), (20, 2), (15, 20), (...   \n",
      "1  Japanese         5  18  [(8, 9), (14, 8), (4, 14), (5, 4), (1, 2), (6,...   \n",
      "2  Japanese         8  33  [(2, 10), (2, 14), (4, 2), (16, 4), (6, 16), (...   \n",
      "3  Japanese        11  30  [(30, 1), (14, 24), (21, 14), (3, 21), (7, 3),...   \n",
      "4  Japanese        12  19  [(19, 13), (16, 19), (2, 16), (4, 10), (4, 15)...   \n",
      "5  Japanese        14  29  [(23, 29), (18, 23), (28, 18), (28, 12), (28, ...   \n",
      "6  Japanese        16  19  [(19, 7), (14, 19), (16, 8), (15, 16), (13, 15...   \n",
      "7  Japanese        21  19  [(9, 10), (14, 9), (18, 14), (7, 8), (16, 7), ...   \n",
      "8  Japanese        25  19  [(11, 6), (18, 11), (13, 5), (18, 13), (10, 8)...   \n",
      "9  Japanese        26  23  [(8, 23), (17, 8), (7, 17), (6, 5), (19, 6), (...   \n",
      "\n",
      "   root  \n",
      "0    10  \n",
      "1    10  \n",
      "2     3  \n",
      "3    30  \n",
      "4    11  \n",
      "5     6  \n",
      "6    14  \n",
      "7    18  \n",
      "8     7  \n",
      "9     3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_df.head(10))  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005ece16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sentence             n          root\n",
      "count  10500.000000  10500.000000  10500.000000\n",
      "mean     494.778000     18.807524      9.844476\n",
      "std      290.256632      8.190593      7.207740\n",
      "min        2.000000      3.000000      1.000000\n",
      "25%      233.500000     13.000000      4.000000\n",
      "50%      483.000000     18.000000      8.000000\n",
      "75%      742.250000     23.000000     14.000000\n",
      "max      995.000000     70.000000     68.000000\n"
     ]
    }
   ],
   "source": [
    "print(train_df.describe())  # Summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc24117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "Japanese      500\n",
      "German        500\n",
      "Arabic        500\n",
      "Portuguese    500\n",
      "Chinese       500\n",
      "Czech         500\n",
      "Turkish       500\n",
      "Thai          500\n",
      "Polish        500\n",
      "Korean        500\n",
      "Icelandic     500\n",
      "Finnish       500\n",
      "Spanish       500\n",
      "Swedish       500\n",
      "Indonesian    500\n",
      "Italian       500\n",
      "French        500\n",
      "Hindi         500\n",
      "English       500\n",
      "Galician      500\n",
      "Russian       500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['language'].value_counts())  # Check language distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7856e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language    0\n",
       "sentence    0\n",
       "n           0\n",
       "edgelist    0\n",
       "root        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()  # Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210e2b6",
   "metadata": {},
   "source": [
    "# Visualization: Sentence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19e338b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(train_df['n'], bins=30, kde=True)\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.xlabel('Number of nodes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67ce21",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_expanded_features(edges):\n",
    "    \"\"\"Compute an expanded set of graph metrics for each node in the graph.\"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Get all nodes\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    # Initialize feature dictionary\n",
    "    features = {node: {} for node in nodes}\n",
    "    \n",
    "    # 1. CENTRALITY MEASURES\n",
    "    # Basic centrality measures\n",
    "    degree_cent = nx.degree_centrality(G)\n",
    "    harmonic_cent = nx.harmonic_centrality(G)\n",
    "    betweenness_cent = nx.betweenness_centrality(G)\n",
    "    pagerank = nx.pagerank(G, alpha=0.85)\n",
    "    katz_cent = nx.katz_centrality_numpy(G, alpha=0.1)\n",
    "    load_cent = nx.load_centrality(G)\n",
    "    closeness_cent = nx.closeness_centrality(G)\n",
    "    \n",
    "    # Additional centrality measures\n",
    "    eigenvector_cent = nx.eigenvector_centrality_numpy(G)\n",
    "    information_cent = nx.information_centrality(G) if nx.is_connected(G) else {n: 0 for n in nodes}\n",
    "    \n",
    "    # Calculate second-order centrality (centrality of neighbors)\n",
    "    second_order_degree = {}\n",
    "    second_order_betweenness = {}\n",
    "    second_order_pagerank = {}\n",
    "    \n",
    "    for node in nodes:\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        if neighbors:\n",
    "            second_order_degree[node] = np.mean([degree_cent[n] for n in neighbors])\n",
    "            second_order_betweenness[node] = np.mean([betweenness_cent[n] for n in neighbors])\n",
    "            second_order_pagerank[node] = np.mean([pagerank[n] for n in neighbors])\n",
    "        else:\n",
    "            second_order_degree[node] = 0\n",
    "            second_order_betweenness[node] = 0\n",
    "            second_order_pagerank[node] = 0\n",
    "    \n",
    "    # 2. LOCAL STRUCTURE MEASURES\n",
    "    # Clustering and triangles\n",
    "    clustering = nx.clustering(G)\n",
    "    triangles = nx.triangles(G)\n",
    "    square_clustering = nx.square_clustering(G)\n",
    "    \n",
    "    # Local efficiency\n",
    "    local_efficiency = {}\n",
    "    for node in nodes:\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        if len(neighbors) > 1:\n",
    "            subgraph = G.subgraph(neighbors)\n",
    "            local_efficiency[node] = nx.global_efficiency(subgraph)\n",
    "        else:\n",
    "            local_efficiency[node] = 0\n",
    "    \n",
    "    # 3. NEIGHBORHOOD METRICS\n",
    "    # Neighborhood sizes at different depths\n",
    "    neighborhood_size_2 = {}\n",
    "    neighborhood_size_3 = {}\n",
    "    for node in nodes:\n",
    "        # Get all nodes within distance 2\n",
    "        dist_2_nodes = set()\n",
    "        for n in G.neighbors(node):\n",
    "            dist_2_nodes.update(G.neighbors(n))\n",
    "        dist_2_nodes.discard(node)  # Remove the original node\n",
    "        neighborhood_size_2[node] = len(dist_2_nodes)\n",
    "        \n",
    "        # Get all nodes within distance 3\n",
    "        dist_3_nodes = set()\n",
    "        for n in dist_2_nodes:\n",
    "            dist_3_nodes.update(G.neighbors(n))\n",
    "        dist_3_nodes.discard(node)  # Remove the original node\n",
    "        dist_3_nodes -= dist_2_nodes  # Remove nodes already counted in distance 2\n",
    "        neighborhood_size_3[node] = len(dist_3_nodes)\n",
    "    \n",
    "    # Average neighbor degree and weighted variants\n",
    "    avg_neighbor_deg = nx.average_neighbor_degree(G)\n",
    "    \n",
    "    # Neighbor degree statistics\n",
    "    neighbor_degree_stats = {}\n",
    "    for node in nodes:\n",
    "        neighbor_degrees = [G.degree(n) for n in G.neighbors(node)] if G.degree(node) > 0 else [0]\n",
    "        if neighbor_degrees:\n",
    "            neighbor_degree_stats[node] = {\n",
    "                'min': min(neighbor_degrees, default=0),\n",
    "                'max': max(neighbor_degrees, default=0),\n",
    "                'median': np.median(neighbor_degrees),\n",
    "                'std': np.std(neighbor_degrees) if len(neighbor_degrees) > 1 else 0,\n",
    "                'skew': stats.skew(neighbor_degrees) if len(neighbor_degrees) > 2 else 0,\n",
    "                'kurtosis': stats.kurtosis(neighbor_degrees) if len(neighbor_degrees) > 3 else 0\n",
    "            }\n",
    "        else:\n",
    "            neighbor_degree_stats[node] = {\n",
    "                'min': 0, 'max': 0, 'median': 0, 'std': 0, 'skew': 0, 'kurtosis': 0\n",
    "            }\n",
    "    \n",
    "    # 4. PATH-BASED METRICS\n",
    "    # Eccentricity and related measures\n",
    "    if nx.is_connected(G):\n",
    "        eccentricity = nx.eccentricity(G)\n",
    "        diameter = nx.diameter(G)\n",
    "        radius = nx.radius(G)\n",
    "        center = nx.center(G)\n",
    "        periphery = nx.periphery(G)\n",
    "        \n",
    "        # Is node in center or periphery\n",
    "        is_center = {node: 1 if node in center else 0 for node in nodes}\n",
    "        is_periphery = {node: 1 if node in periphery else 0 for node in nodes}\n",
    "    else:\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        subgraph = G.subgraph(largest_cc)\n",
    "        \n",
    "        # Default values for nodes not in largest component\n",
    "        eccentricity = {node: 0 for node in nodes}\n",
    "        is_center = {node: 0 for node in nodes}\n",
    "        is_periphery = {node: 0 for node in nodes}\n",
    "        \n",
    "        # Calculate for nodes in the largest component\n",
    "        subgraph_eccentricity = nx.eccentricity(subgraph)\n",
    "        subgraph_center = nx.center(subgraph)\n",
    "        subgraph_periphery = nx.periphery(subgraph)\n",
    "        \n",
    "        for node in largest_cc:\n",
    "            eccentricity[node] = subgraph_eccentricity[node]\n",
    "            is_center[node] = 1 if node in subgraph_center else 0\n",
    "            is_periphery[node] = 1 if node in subgraph_periphery else 0\n",
    "    \n",
    "    # Average shortest path length to all other nodes\n",
    "    avg_shortest_path = {}\n",
    "    for node in nodes:\n",
    "        path_lengths = []\n",
    "        for target in nodes:\n",
    "            if node != target:\n",
    "                try:\n",
    "                    path_lengths.append(nx.shortest_path_length(G, node, target))\n",
    "                except nx.NetworkXNoPath:\n",
    "                    # If no path exists, can use infinity or a large value\n",
    "                    # Here we'll use the node count as a penalty\n",
    "                    path_lengths.append(len(nodes))\n",
    "        avg_shortest_path[node] = np.mean(path_lengths) if path_lengths else 0\n",
    "    \n",
    "    # 5. COMMUNITY STRUCTURE\n",
    "    # Community detection using Louvain method\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    \n",
    "    # Count nodes in each community\n",
    "    community_sizes = Counter(partition.values())\n",
    "    \n",
    "    # Community-based features\n",
    "    community_features = {}\n",
    "    for node in nodes:\n",
    "        if node in partition:\n",
    "            community_id = partition[node]\n",
    "            community_size = community_sizes[community_id]\n",
    "            \n",
    "            # Calculate ratio of connections within vs outside community\n",
    "            node_degree = G.degree(node)\n",
    "            internal_connections = sum(1 for neighbor in G.neighbors(node) \n",
    "                                       if neighbor in partition and partition[neighbor] == community_id)\n",
    "            \n",
    "            if node_degree > 0:\n",
    "                internal_connection_ratio = internal_connections / node_degree\n",
    "            else:\n",
    "                internal_connection_ratio = 0\n",
    "                \n",
    "            community_features[node] = {\n",
    "                'community_id': community_id,\n",
    "                'community_size': community_size,\n",
    "                'internal_connection_ratio': internal_connection_ratio\n",
    "            }\n",
    "        else:\n",
    "            community_features[node] = {\n",
    "                'community_id': -1,\n",
    "                'community_size': 1,\n",
    "                'internal_connection_ratio': 0\n",
    "            }\n",
    "    \n",
    "    # 6. TOPOLOGICAL FEATURES\n",
    "    # Core number (k-core decomposition)\n",
    "    core_numbers = nx.core_number(G)\n",
    "    \n",
    "    # Voterank (influential nodes based on voting)\n",
    "    voterank_scores = {}\n",
    "    max_voterank = min(20, len(nodes))  # Limit computation\n",
    "    voterank_nodes = nx.voterank(G, max_voterank)\n",
    "    for i, node in enumerate(voterank_nodes):\n",
    "        voterank_scores[node] = max_voterank - i\n",
    "    \n",
    "    for node in nodes:\n",
    "        if node not in voterank_scores:\n",
    "            voterank_scores[node] = 0\n",
    "    \n",
    "    # 7. SPECTRAL FEATURES\n",
    "    # Compute Laplacian eigenvalues for the graph\n",
    "    L = nx.normalized_laplacian_matrix(G).todense()\n",
    "    try:\n",
    "        eigenvalues = np.linalg.eigvalsh(L)\n",
    "        algebraic_connectivity = eigenvalues[1] if len(eigenvalues) > 1 else 0\n",
    "        spectral_gap = eigenvalues[1] - eigenvalues[0] if len(eigenvalues) > 1 else 0\n",
    "    except:\n",
    "        algebraic_connectivity = 0\n",
    "        spectral_gap = 0\n",
    "    \n",
    "    # 8. CUSTOM FEATURES\n",
    "    # Distance to highest degree node\n",
    "    max_degree_node = max(degree_cent, key=degree_cent.get)\n",
    "    dist_to_max_degree = {}\n",
    "    for node in nodes:\n",
    "        if node == max_degree_node:\n",
    "            dist_to_max_degree[node] = 0\n",
    "        else:\n",
    "            try:\n",
    "                dist_to_max_degree[node] = nx.shortest_path_length(G, node, max_degree_node)\n",
    "            except nx.NetworkXNoPath:\n",
    "                dist_to_max_degree[node] = len(nodes)  # No path exists\n",
    "    \n",
    "    # Relative position features\n",
    "    degree_rank = {}\n",
    "    betweenness_rank = {}\n",
    "    pagerank_rank = {}\n",
    "    \n",
    "    sorted_degree = sorted([(node, val) for node, val in degree_cent.items()], \n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "    sorted_betweenness = sorted([(node, val) for node, val in betweenness_cent.items()], \n",
    "                                key=lambda x: x[1], reverse=True)\n",
    "    sorted_pagerank = sorted([(node, val) for node, val in pagerank.items()], \n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i, (node, _) in enumerate(sorted_degree):\n",
    "        degree_rank[node] = i + 1\n",
    "    \n",
    "    for i, (node, _) in enumerate(sorted_betweenness):\n",
    "        betweenness_rank[node] = i + 1\n",
    "    \n",
    "    for i, (node, _) in enumerate(sorted_pagerank):\n",
    "        pagerank_rank[node] = i + 1\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    degree_percentile = {}\n",
    "    betweenness_percentile = {}\n",
    "    pagerank_percentile = {}\n",
    "    \n",
    "    n_nodes = len(nodes)\n",
    "    for node in nodes:\n",
    "        degree_percentile[node] = (n_nodes - degree_rank[node] + 1) / n_nodes * 100\n",
    "        betweenness_percentile[node] = (n_nodes - betweenness_rank[node] + 1) / n_nodes * 100\n",
    "        pagerank_percentile[node] = (n_nodes - pagerank_rank[node] + 1) / n_nodes * 100\n",
    "    \n",
    "    # 9. GRAPH-LEVEL CONTEXT\n",
    "    # Global graph properties (same for all nodes)\n",
    "    global_features = {\n",
    "        'graph_density': nx.density(G),\n",
    "        'graph_transitivity': nx.transitivity(G),\n",
    "        'graph_num_nodes': len(nodes),\n",
    "        'graph_num_edges': G.number_of_edges(),\n",
    "        'graph_avg_degree': 2 * G.number_of_edges() / len(nodes) if len(nodes) > 0 else 0,\n",
    "        'graph_max_degree': max([G.degree(n) for n in nodes], default=0)\n",
    "    }\n",
    "    \n",
    "    # 10. COMPILE ALL FEATURES\n",
    "    for node in nodes:\n",
    "        # Basic centrality measures\n",
    "        features[node]['degree_cent'] = degree_cent[node]\n",
    "        features[node]['harmonic_cent'] = harmonic_cent[node]\n",
    "        features[node]['betweenness_cent'] = betweenness_cent[node]\n",
    "        features[node]['pagerank'] = pagerank[node]\n",
    "        features[node]['katz_cent'] = katz_cent[node]\n",
    "        features[node]['load_cent'] = load_cent[node]\n",
    "        features[node]['closeness_cent'] = closeness_cent[node]\n",
    "        features[node]['eigenvector_cent'] = eigenvector_cent[node]\n",
    "        features[node]['information_cent'] = information_cent[node]\n",
    "        \n",
    "        # Second-order centrality\n",
    "        features[node]['second_order_degree'] = second_order_degree[node]\n",
    "        features[node]['second_order_betweenness'] = second_order_betweenness[node]\n",
    "        features[node]['second_order_pagerank'] = second_order_pagerank[node]\n",
    "        \n",
    "        # Local structure\n",
    "        features[node]['clustering_coef'] = clustering[node]\n",
    "        features[node]['triangles'] = triangles[node]\n",
    "        features[node]['square_clustering'] = square_clustering[node]\n",
    "        features[node]['local_efficiency'] = local_efficiency[node]\n",
    "        \n",
    "        # Neighborhood metrics\n",
    "        features[node]['neighborhood_size_2'] = neighborhood_size_2[node]\n",
    "        features[node]['neighborhood_size_3'] = neighborhood_size_3[node]\n",
    "        features[node]['avg_neighbor_deg'] = avg_neighbor_deg[node]\n",
    "        features[node]['min_neighbor_deg'] = neighbor_degree_stats[node]['min']\n",
    "        features[node]['max_neighbor_deg'] = neighbor_degree_stats[node]['max']\n",
    "        features[node]['median_neighbor_deg'] = neighbor_degree_stats[node]['median']\n",
    "        features[node]['std_neighbor_deg'] = neighbor_degree_stats[node]['std']\n",
    "        features[node]['skew_neighbor_deg'] = neighbor_degree_stats[node]['skew']\n",
    "        features[node]['kurtosis_neighbor_deg'] = neighbor_degree_stats[node]['kurtosis']\n",
    "        \n",
    "        # Path-based metrics\n",
    "        features[node]['eccentricity'] = eccentricity[node]\n",
    "        features[node]['is_center'] = is_center[node]\n",
    "        features[node]['is_periphery'] = is_periphery[node]\n",
    "        features[node]['avg_shortest_path'] = avg_shortest_path[node]\n",
    "        \n",
    "        # Community structure\n",
    "        features[node]['community_id'] = community_features[node]['community_id']\n",
    "        features[node]['community_size'] = community_features[node]['community_size']\n",
    "        features[node]['internal_connection_ratio'] = community_features[node]['internal_connection_ratio']\n",
    "        \n",
    "        # Topological features\n",
    "        features[node]['core_number'] = core_numbers[node]\n",
    "        features[node]['voterank_score'] = voterank_scores[node]\n",
    "        \n",
    "        # Relative position features\n",
    "        features[node]['degree_rank'] = degree_rank[node]\n",
    "        features[node]['betweenness_rank'] = betweenness_rank[node]\n",
    "        features[node]['pagerank_rank'] = pagerank_rank[node]\n",
    "        features[node]['degree_percentile'] = degree_percentile[node]\n",
    "        features[node]['betweenness_percentile'] = betweenness_percentile[node]\n",
    "        features[node]['pagerank_percentile'] = pagerank_percentile[node]\n",
    "        features[node]['dist_to_max_degree'] = dist_to_max_degree[node]\n",
    "        \n",
    "        # Graph-level context\n",
    "        for key, value in global_features.items():\n",
    "            features[node][key] = value\n",
    "        \n",
    "        # Network ratios and derived metrics\n",
    "        if global_features['graph_max_degree'] > 0:\n",
    "            features[node]['degree_ratio_to_max'] = G.degree(node) / global_features['graph_max_degree']\n",
    "        else:\n",
    "            features[node]['degree_ratio_to_max'] = 0\n",
    "            \n",
    "        features[node]['degree_centrality_to_density_ratio'] = degree_cent[node] / global_features['graph_density'] if global_features['graph_density'] > 0 else 0\n",
    "        \n",
    "        # Additional derived features\n",
    "        features[node]['harmonic_to_degree_ratio'] = harmonic_cent[node] / degree_cent[node] if degree_cent[node] > 0 else 0\n",
    "        features[node]['betweenness_to_degree_ratio'] = betweenness_cent[node] / degree_cent[node] if degree_cent[node] > 0 else 0\n",
    "        features[node]['pagerank_to_degree_ratio'] = pagerank[node] / degree_cent[node] if degree_cent[node] > 0 else 0\n",
    "        \n",
    "        # Local assortativity: correlation between node degree and neighbor degrees\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        if neighbors:\n",
    "            node_degree = G.degree(node)\n",
    "            neighbor_degrees = [G.degree(n) for n in neighbors]\n",
    "            try:\n",
    "                if len(neighbor_degrees) > 1 and np.std(neighbor_degrees) > 0:\n",
    "                    features[node]['local_assortativity'] = np.corrcoef(\n",
    "                        [node_degree] * len(neighbors), neighbor_degrees)[0, 1]\n",
    "                else:\n",
    "                    features[node]['local_assortativity'] = 0\n",
    "            except:\n",
    "                features[node]['local_assortativity'] = 0\n",
    "        else:\n",
    "            features[node]['local_assortativity'] = 0\n",
    "    \n",
    "    # 11. ADDITIONAL DERIVED FEATURES\n",
    "    for node in nodes:\n",
    "        # Create combination features\n",
    "        features[node]['degree_betweenness_product'] = features[node]['degree_cent'] * features[node]['betweenness_cent']\n",
    "        features[node]['pagerank_clustering_product'] = features[node]['pagerank'] * features[node]['clustering_coef']\n",
    "        features[node]['centrality_harmonic_mean'] = stats.hmean([\n",
    "            features[node]['degree_cent'] + 1e-8,\n",
    "            features[node]['betweenness_cent'] + 1e-8,\n",
    "            features[node]['pagerank'] + 1e-8\n",
    "        ])\n",
    "        \n",
    "        # Log transformations of skewed metrics\n",
    "        features[node]['log_betweenness'] = np.log1p(features[node]['betweenness_cent'])\n",
    "        features[node]['log_triangles'] = np.log1p(features[node]['triangles'])\n",
    "        \n",
    "        # More complex derived metrics\n",
    "        features[node]['clustering_degree_ratio'] = features[node]['clustering_coef'] / features[node]['degree_cent'] if features[node]['degree_cent'] > 0 else 0\n",
    "        features[node]['betweenness_eigenvector_ratio'] = features[node]['betweenness_cent'] / features[node]['eigenvector_cent'] if features[node]['eigenvector_cent'] > 0 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "def build_expanded_training_data(train_df):\n",
    "    train_rows = []\n",
    "    for idx, row in train_df.iterrows():\n",
    "        edges = ast.literal_eval(row['edgelist'])\n",
    "        \n",
    "        # Compute expanded features for each node\n",
    "        all_features = compute_expanded_features(edges)\n",
    "        \n",
    "        root = row['root']\n",
    "        for node, feats in all_features.items():\n",
    "            node_data = {\n",
    "                'language': row['language'],\n",
    "                'sentence': row['sentence'],\n",
    "                'node': node,\n",
    "                'n_nodes': row['n'],\n",
    "                'target': 1 if node == root else 0\n",
    "            }\n",
    "            \n",
    "            # Add all the features\n",
    "            for feature_name, feature_value in feats.items():\n",
    "                node_data[feature_name] = feature_value\n",
    "                \n",
    "            train_rows.append(node_data)\n",
    "    \n",
    "    return train_rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "719199d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/km8wh4ms46vbb2wjtr90_gn00000gn/T/ipykernel_95704/1543172991.py:91: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  'skew': stats.skew(neighbor_degrees) if len(neighbor_degrees) > 2 else 0,\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/sarasaad/Documents/BDMA /UPC/ML/Project/tree-root-prediction/.venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/var/folders/t2/km8wh4ms46vbb2wjtr90_gn00000gn/T/ipykernel_95704/1543172991.py:92: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  'kurtosis': stats.kurtosis(neighbor_degrees) if len(neighbor_degrees) > 3 else 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>node</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>target</th>\n",
       "      <th>degree_cent</th>\n",
       "      <th>harmonic_cent</th>\n",
       "      <th>betweenness_cent</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>katz_cent</th>\n",
       "      <th>...</th>\n",
       "      <th>betweenness_to_degree_ratio</th>\n",
       "      <th>pagerank_to_degree_ratio</th>\n",
       "      <th>local_assortativity</th>\n",
       "      <th>degree_betweenness_product</th>\n",
       "      <th>pagerank_clustering_product</th>\n",
       "      <th>centrality_harmonic_mean</th>\n",
       "      <th>log_betweenness</th>\n",
       "      <th>log_triangles</th>\n",
       "      <th>clustering_degree_ratio</th>\n",
       "      <th>betweenness_eigenvector_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>5.823846</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>0.209086</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.534217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.043759e-02</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>4.561122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0.188298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>6.991703</td>\n",
       "      <td>0.255411</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>0.228660</td>\n",
       "      <td>...</td>\n",
       "      <td>1.873016</td>\n",
       "      <td>0.490609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145213e-01</td>\n",
       "      <td>0.227463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>5.157179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025477</td>\n",
       "      <td>0.190256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>7.146825</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.042552</td>\n",
       "      <td>0.213357</td>\n",
       "      <td>...</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.468071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.955653e-02</td>\n",
       "      <td>0.271315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.057609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197474</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.005159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032147</td>\n",
       "      <td>0.205491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999999e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197475</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>6.034524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.211939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197476</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>6.034524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.211939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197477</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6.701190</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.232488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.444999e-02</td>\n",
       "      <td>0.105361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197478</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.005159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032147</td>\n",
       "      <td>0.205491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999999e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197479 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language  sentence  node  n_nodes  target  degree_cent  harmonic_cent  \\\n",
       "0       Japanese         2     6       23       0     0.090909       5.823846   \n",
       "1       Japanese         2     4       23       0     0.045455       4.561122   \n",
       "2       Japanese         2     2       23       0     0.136364       6.991703   \n",
       "3       Japanese         2    23       23       0     0.045455       5.157179   \n",
       "4       Japanese         2    20       23       0     0.090909       7.146825   \n",
       "...          ...       ...   ...      ...     ...          ...            ...   \n",
       "197474   Russian       995    19       19       0     0.055556       5.005159   \n",
       "197475   Russian       995     1       19       0     0.055556       6.034524   \n",
       "197476   Russian       995    14       19       0     0.055556       6.034524   \n",
       "197477   Russian       995     5       19       0     0.111111       6.701190   \n",
       "197478   Russian       995    16       19       0     0.055556       5.005159   \n",
       "\n",
       "        betweenness_cent  pagerank  katz_cent  ...  \\\n",
       "0               0.090909  0.048565   0.209086  ...   \n",
       "1               0.000000  0.027162   0.188298  ...   \n",
       "2               0.255411  0.066901   0.228660  ...   \n",
       "3               0.000000  0.025477   0.190256  ...   \n",
       "4               0.311688  0.042552   0.213357  ...   \n",
       "...                  ...       ...        ...  ...   \n",
       "197474          0.000000  0.032147   0.205491  ...   \n",
       "197475          0.000000  0.029739   0.211939  ...   \n",
       "197476          0.000000  0.029739   0.211939  ...   \n",
       "197477          0.111111  0.057065   0.232488  ...   \n",
       "197478          0.000000  0.032147   0.205491  ...   \n",
       "\n",
       "        betweenness_to_degree_ratio  pagerank_to_degree_ratio  \\\n",
       "0                          1.000000                  0.534217   \n",
       "1                          0.000000                  0.597554   \n",
       "2                          1.873016                  0.490609   \n",
       "3                          0.000000                  0.560504   \n",
       "4                          3.428571                  0.468071   \n",
       "...                             ...                       ...   \n",
       "197474                     0.000000                  0.578643   \n",
       "197475                     0.000000                  0.535310   \n",
       "197476                     0.000000                  0.535310   \n",
       "197477                     1.000000                  0.513582   \n",
       "197478                     0.000000                  0.578643   \n",
       "\n",
       "        local_assortativity  degree_betweenness_product  \\\n",
       "0                       NaN                    0.008264   \n",
       "1                       0.0                    0.000000   \n",
       "2                       NaN                    0.034829   \n",
       "3                       0.0                    0.000000   \n",
       "4                       0.0                    0.028335   \n",
       "...                     ...                         ...   \n",
       "197474                  0.0                    0.000000   \n",
       "197475                  0.0                    0.000000   \n",
       "197476                  0.0                    0.000000   \n",
       "197477                  NaN                    0.012346   \n",
       "197478                  0.0                    0.000000   \n",
       "\n",
       "        pagerank_clustering_product  centrality_harmonic_mean  \\\n",
       "0                               0.0              7.043759e-02   \n",
       "1                               0.0              2.999998e-08   \n",
       "2                               0.0              1.145213e-01   \n",
       "3                               0.0              2.999998e-08   \n",
       "4                               0.0              7.955653e-02   \n",
       "...                             ...                       ...   \n",
       "197474                          0.0              2.999999e-08   \n",
       "197475                          0.0              2.999998e-08   \n",
       "197476                          0.0              2.999998e-08   \n",
       "197477                          0.0              8.444999e-02   \n",
       "197478                          0.0              2.999999e-08   \n",
       "\n",
       "        log_betweenness  log_triangles  clustering_degree_ratio  \\\n",
       "0              0.087011            0.0                      0.0   \n",
       "1              0.000000            0.0                      0.0   \n",
       "2              0.227463            0.0                      0.0   \n",
       "3              0.000000            0.0                      0.0   \n",
       "4              0.271315            0.0                      0.0   \n",
       "...                 ...            ...                      ...   \n",
       "197474         0.000000            0.0                      0.0   \n",
       "197475         0.000000            0.0                      0.0   \n",
       "197476         0.000000            0.0                      0.0   \n",
       "197477         0.105361            0.0                      0.0   \n",
       "197478         0.000000            0.0                      0.0   \n",
       "\n",
       "        betweenness_eigenvector_ratio  \n",
       "0                            0.608067  \n",
       "1                            0.000000  \n",
       "2                            0.991095  \n",
       "3                            0.000000  \n",
       "4                            1.057609  \n",
       "...                               ...  \n",
       "197474                       0.000000  \n",
       "197475                       0.000000  \n",
       "197476                       0.000000  \n",
       "197477                       0.411256  \n",
       "197478                       0.000000  \n",
       "\n",
       "[197479 rows x 65 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage:\n",
    "train_rows = build_expanded_training_data(train_df)\n",
    "expanded_train = pd.DataFrame(train_rows)\n",
    "expanded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b006049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features to analyze: 61\n",
      "Feature Quality Analysis Report\n",
      "===========================\n",
      "\n",
      "Total Features: 61\n",
      "\n",
      "Features with NaN values (top 10):\n",
      "  local_assortativity: 49.67% NaN (98096 values)\n",
      "  skew_neighbor_deg: 0.97% NaN (1907 values)\n",
      "  kurtosis_neighbor_deg: 0.16% NaN (310 values)\n",
      "\n",
      "Features with Inf values (top 10):\n",
      "\n",
      "Constant features (no variation):\n",
      "  clustering_coef: constant value\n",
      "  triangles: constant value\n",
      "  square_clustering: constant value\n",
      "  local_efficiency: constant value\n",
      "  core_number: constant value\n",
      "  graph_transitivity: constant value\n",
      "  local_assortativity: constant value\n",
      "  pagerank_clustering_product: constant value\n",
      "  log_triangles: constant value\n",
      "  clustering_degree_ratio: constant value\n",
      "\n",
      "Features with very low variance:\n",
      "\n",
      "Features with >90% zero values:\n",
      "  clustering_coef: 100.00% zeros\n",
      "  triangles: 100.00% zeros\n",
      "  square_clustering: 100.00% zeros\n",
      "  local_efficiency: 100.00% zeros\n",
      "  graph_transitivity: 100.00% zeros\n",
      "  pagerank_clustering_product: 100.00% zeros\n",
      "  log_triangles: 100.00% zeros\n",
      "  clustering_degree_ratio: 100.00% zeros\n",
      "  kurtosis_neighbor_deg: 92.66% zeros\n",
      "  is_center: 92.07% zeros\n",
      "\n",
      "Recommendations:\n",
      "- Handle NaN values: Some features contain NaN values that should be filled or removed\n",
      "- Remove constant features: These features provide no information for modeling\n",
      "\n",
      "Dropping 10 constant columns\n",
      "Total features to analyze: 51\n",
      "Feature Quality Analysis Report\n",
      "===========================\n",
      "\n",
      "Total Features: 51\n",
      "\n",
      "Features with NaN values (top 10):\n",
      "\n",
      "Features with Inf values (top 10):\n",
      "\n",
      "Constant features (no variation):\n",
      "\n",
      "Features with very low variance:\n",
      "\n",
      "Features with >90% zero values:\n",
      "  kurtosis_neighbor_deg: 92.82% zeros\n",
      "  is_center: 92.07% zeros\n",
      "\n",
      "Recommendations:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_feature_quality(df):\n",
    "    \"\"\"\n",
    "    Analyzes each feature in the dataframe to identify empty, NaN, or problematic values.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Get all columns except categorical/identifier columns\n",
    "    feature_cols = [col for col in df.columns if col not in ['language', 'sentence', 'node', 'target']]\n",
    "    \n",
    "    print(f\"Total features to analyze: {len(feature_cols)}\")\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        # Check for NaN values\n",
    "        nan_count = df[col].isna().sum()\n",
    "        nan_percent = (nan_count / len(df)) * 100\n",
    "        \n",
    "        # Check for infinity values\n",
    "        inf_count = np.isinf(df[col].replace([np.inf, -np.inf], np.nan)).sum()\n",
    "        inf_percent = (inf_count / len(df)) * 100\n",
    "        \n",
    "        # Check for zero values\n",
    "        zero_count = (df[col] == 0).sum()\n",
    "        zero_percent = (zero_count / len(df)) * 100\n",
    "        \n",
    "        # Check for negative values (might be problematic for certain metrics)\n",
    "        neg_count = (df[col] < 0).sum() if df[col].dtype in [np.int64, np.float64] else 0\n",
    "        neg_percent = (neg_count / len(df)) * 100 if df[col].dtype in [np.int64, np.float64] else 0\n",
    "        \n",
    "        # Check for constants\n",
    "        is_constant = df[col].nunique() <= 1\n",
    "        \n",
    "        # Check for variance too low\n",
    "        variance = df[col].var() if df[col].dtype in [np.int64, np.float64] else None\n",
    "        low_variance = variance is not None and variance < 0.0001\n",
    "        \n",
    "        results[col] = {\n",
    "            'nan_count': nan_count,\n",
    "            'nan_percent': nan_percent,\n",
    "            'inf_count': inf_count,\n",
    "            'inf_percent': inf_percent,\n",
    "            'zero_count': zero_count,\n",
    "            'zero_percent': zero_percent,\n",
    "            'neg_count': neg_count,\n",
    "            'neg_percent': neg_percent,\n",
    "            'is_constant': is_constant,\n",
    "            'variance': variance,\n",
    "            'low_variance': low_variance,\n",
    "            'dtype': str(df[col].dtype)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def feature_quality_report(df):\n",
    "    \"\"\"\n",
    "    Generates a human-readable report on feature quality.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the features\n",
    "        \n",
    "    Returns:\n",
    "        String containing the report\n",
    "    \"\"\"\n",
    "    analysis = analyze_feature_quality(df)\n",
    "    \n",
    "    # Sort features by problematic metrics\n",
    "    features_by_nan = sorted([(col, data['nan_percent']) for col, data in analysis.items()], \n",
    "                             key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    features_by_inf = sorted([(col, data['inf_percent']) for col, data in analysis.items()], \n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    features_by_const = [(col, data) for col, data in analysis.items() if data['is_constant']]\n",
    "    \n",
    "    features_by_low_var = [(col, data) for col, data in analysis.items() \n",
    "                          if not data['is_constant'] and data['low_variance']]\n",
    "    \n",
    "    # Generate report\n",
    "    report = \"Feature Quality Analysis Report\\n\"\n",
    "    report += \"===========================\\n\\n\"\n",
    "    \n",
    "    report += f\"Total Features: {len(analysis)}\\n\\n\"\n",
    "    \n",
    "    # Report on NaN values\n",
    "    report += \"Features with NaN values (top 10):\\n\"\n",
    "    for col, percent in features_by_nan[:10]:\n",
    "        if percent > 0:\n",
    "            report += f\"  {col}: {percent:.2f}% NaN ({analysis[col]['nan_count']} values)\\n\"\n",
    "    report += \"\\n\"\n",
    "    \n",
    "    # Report on Inf values\n",
    "    report += \"Features with Inf values (top 10):\\n\"\n",
    "    for col, percent in features_by_inf[:10]:\n",
    "        if percent > 0:\n",
    "            report += f\"  {col}: {percent:.2f}% Inf ({analysis[col]['inf_count']} values)\\n\"\n",
    "    report += \"\\n\"\n",
    "    \n",
    "    # Report on constant features\n",
    "    report += \"Constant features (no variation):\\n\"\n",
    "    for col, data in features_by_const:\n",
    "        report += f\"  {col}: constant value\\n\"\n",
    "    report += \"\\n\"\n",
    "    \n",
    "    # Report on low variance features\n",
    "    report += \"Features with very low variance:\\n\"\n",
    "    for col, data in features_by_low_var[:10]:\n",
    "        report += f\"  {col}: variance = {data['variance']:.8f}\\n\"\n",
    "    report += \"\\n\"\n",
    "    \n",
    "    # Report on features with high zero percentage\n",
    "    high_zero_features = [(col, data['zero_percent']) for col, data in analysis.items() \n",
    "                        if data['zero_percent'] > 90]\n",
    "    high_zero_features.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    report += \"Features with >90% zero values:\\n\"\n",
    "    for col, percent in high_zero_features:\n",
    "        report += f\"  {col}: {percent:.2f}% zeros\\n\"\n",
    "    report += \"\\n\"\n",
    "    \n",
    "    # Report on potentially problematic feature pairs\n",
    "    report += \"Recommendations:\\n\"\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if any(data['nan_percent'] > 0 for data in analysis.values()):\n",
    "        report += \"- Handle NaN values: Some features contain NaN values that should be filled or removed\\n\"\n",
    "    \n",
    "    # Check for infinity values\n",
    "    if any(data['inf_percent'] > 0 for data in analysis.values()):\n",
    "        report += \"- Handle infinity values: Some features contain Inf values that should be replaced\\n\"\n",
    "    \n",
    "    # Check for constants\n",
    "    if features_by_const:\n",
    "        report += \"- Remove constant features: These features provide no information for modeling\\n\"\n",
    "    \n",
    "    # Check for low variance\n",
    "    if features_by_low_var:\n",
    "        report += \"- Consider removing low variance features: These features may not provide much signal\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "def fix_problematic_features(df, replace_nan=True, replace_inf=True, drop_constant=True):\n",
    "    \"\"\"\n",
    "    Fixes common issues in the feature dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the features\n",
    "        replace_nan: Whether to replace NaN values (with 0)\n",
    "        replace_inf: Whether to replace infinity values\n",
    "        drop_constant: Whether to drop constant columns\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Get feature columns (non-identifier columns)\n",
    "    feature_cols = [col for col in df.columns if col not in ['language', 'sentence', 'node', 'target']]\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    if replace_nan:\n",
    "        df_clean[feature_cols] = df_clean[feature_cols].fillna(0)\n",
    "    \n",
    "    # Replace infinity values with large values\n",
    "    if replace_inf:\n",
    "        for col in feature_cols:\n",
    "            if df_clean[col].dtype in [np.float64, np.int64]:\n",
    "                df_clean[col] = df_clean[col].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # Drop constant columns\n",
    "    if drop_constant:\n",
    "        constant_cols = [col for col in feature_cols if df_clean[col].nunique() <= 1]\n",
    "        if constant_cols:\n",
    "            print(f\"Dropping {len(constant_cols)} constant columns\")\n",
    "            df_clean = df_clean.drop(columns=constant_cols)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Example usage:\n",
    "analysis_report = feature_quality_report(expanded_train)\n",
    "print(analysis_report)\n",
    "# \n",
    "# # Fix issues in the dataset\n",
    "cleaned_df = fix_problematic_features(expanded_train)\n",
    "# \n",
    "# # Verify the cleaning worked\n",
    "print(feature_quality_report(cleaned_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f300626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>node</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>target</th>\n",
       "      <th>degree_cent</th>\n",
       "      <th>harmonic_cent</th>\n",
       "      <th>betweenness_cent</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>katz_cent</th>\n",
       "      <th>...</th>\n",
       "      <th>graph_max_degree</th>\n",
       "      <th>degree_ratio_to_max</th>\n",
       "      <th>degree_centrality_to_density_ratio</th>\n",
       "      <th>harmonic_to_degree_ratio</th>\n",
       "      <th>betweenness_to_degree_ratio</th>\n",
       "      <th>pagerank_to_degree_ratio</th>\n",
       "      <th>degree_betweenness_product</th>\n",
       "      <th>centrality_harmonic_mean</th>\n",
       "      <th>log_betweenness</th>\n",
       "      <th>betweenness_eigenvector_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>5.823846</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>0.209086</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>64.062302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.534217</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>7.043759e-02</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>0.608067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>4.561122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0.188298</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>100.344689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>6.991703</td>\n",
       "      <td>0.255411</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>0.228660</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.568182</td>\n",
       "      <td>51.272487</td>\n",
       "      <td>1.873016</td>\n",
       "      <td>0.490609</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>1.145213e-01</td>\n",
       "      <td>0.227463</td>\n",
       "      <td>0.991095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>5.157179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025477</td>\n",
       "      <td>0.190256</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>113.457937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>7.146825</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.042552</td>\n",
       "      <td>0.213357</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>78.615079</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.468071</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>7.955653e-02</td>\n",
       "      <td>0.271315</td>\n",
       "      <td>1.057609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197474</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.005159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032147</td>\n",
       "      <td>0.205491</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>90.092857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999999e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197475</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>6.034524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.211939</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>108.621429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197476</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>6.034524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.211939</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>108.621429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999998e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197477</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6.701190</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.232488</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>60.310714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513582</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>8.444999e-02</td>\n",
       "      <td>0.105361</td>\n",
       "      <td>0.411256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197478</th>\n",
       "      <td>Russian</td>\n",
       "      <td>995</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.005159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032147</td>\n",
       "      <td>0.205491</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>90.092857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999999e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197479 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language  sentence  node  n_nodes  target  degree_cent  harmonic_cent  \\\n",
       "0       Japanese         2     6       23       0     0.090909       5.823846   \n",
       "1       Japanese         2     4       23       0     0.045455       4.561122   \n",
       "2       Japanese         2     2       23       0     0.136364       6.991703   \n",
       "3       Japanese         2    23       23       0     0.045455       5.157179   \n",
       "4       Japanese         2    20       23       0     0.090909       7.146825   \n",
       "...          ...       ...   ...      ...     ...          ...            ...   \n",
       "197474   Russian       995    19       19       0     0.055556       5.005159   \n",
       "197475   Russian       995     1       19       0     0.055556       6.034524   \n",
       "197476   Russian       995    14       19       0     0.055556       6.034524   \n",
       "197477   Russian       995     5       19       0     0.111111       6.701190   \n",
       "197478   Russian       995    16       19       0     0.055556       5.005159   \n",
       "\n",
       "        betweenness_cent  pagerank  katz_cent  ...  graph_max_degree  \\\n",
       "0               0.090909  0.048565   0.209086  ...                 3   \n",
       "1               0.000000  0.027162   0.188298  ...                 3   \n",
       "2               0.255411  0.066901   0.228660  ...                 3   \n",
       "3               0.000000  0.025477   0.190256  ...                 3   \n",
       "4               0.311688  0.042552   0.213357  ...                 3   \n",
       "...                  ...       ...        ...  ...               ...   \n",
       "197474          0.000000  0.032147   0.205491  ...                 5   \n",
       "197475          0.000000  0.029739   0.211939  ...                 5   \n",
       "197476          0.000000  0.029739   0.211939  ...                 5   \n",
       "197477          0.111111  0.057065   0.232488  ...                 5   \n",
       "197478          0.000000  0.032147   0.205491  ...                 5   \n",
       "\n",
       "        degree_ratio_to_max  degree_centrality_to_density_ratio  \\\n",
       "0                  0.666667                            1.045455   \n",
       "1                  0.333333                            0.522727   \n",
       "2                  1.000000                            1.568182   \n",
       "3                  0.333333                            0.522727   \n",
       "4                  0.666667                            1.045455   \n",
       "...                     ...                                 ...   \n",
       "197474             0.200000                            0.527778   \n",
       "197475             0.200000                            0.527778   \n",
       "197476             0.200000                            0.527778   \n",
       "197477             0.400000                            1.055556   \n",
       "197478             0.200000                            0.527778   \n",
       "\n",
       "        harmonic_to_degree_ratio  betweenness_to_degree_ratio  \\\n",
       "0                      64.062302                     1.000000   \n",
       "1                     100.344689                     0.000000   \n",
       "2                      51.272487                     1.873016   \n",
       "3                     113.457937                     0.000000   \n",
       "4                      78.615079                     3.428571   \n",
       "...                          ...                          ...   \n",
       "197474                 90.092857                     0.000000   \n",
       "197475                108.621429                     0.000000   \n",
       "197476                108.621429                     0.000000   \n",
       "197477                 60.310714                     1.000000   \n",
       "197478                 90.092857                     0.000000   \n",
       "\n",
       "        pagerank_to_degree_ratio  degree_betweenness_product  \\\n",
       "0                       0.534217                    0.008264   \n",
       "1                       0.597554                    0.000000   \n",
       "2                       0.490609                    0.034829   \n",
       "3                       0.560504                    0.000000   \n",
       "4                       0.468071                    0.028335   \n",
       "...                          ...                         ...   \n",
       "197474                  0.578643                    0.000000   \n",
       "197475                  0.535310                    0.000000   \n",
       "197476                  0.535310                    0.000000   \n",
       "197477                  0.513582                    0.012346   \n",
       "197478                  0.578643                    0.000000   \n",
       "\n",
       "        centrality_harmonic_mean  log_betweenness  \\\n",
       "0                   7.043759e-02         0.087011   \n",
       "1                   2.999998e-08         0.000000   \n",
       "2                   1.145213e-01         0.227463   \n",
       "3                   2.999998e-08         0.000000   \n",
       "4                   7.955653e-02         0.271315   \n",
       "...                          ...              ...   \n",
       "197474              2.999999e-08         0.000000   \n",
       "197475              2.999998e-08         0.000000   \n",
       "197476              2.999998e-08         0.000000   \n",
       "197477              8.444999e-02         0.105361   \n",
       "197478              2.999999e-08         0.000000   \n",
       "\n",
       "        betweenness_eigenvector_ratio  \n",
       "0                            0.608067  \n",
       "1                            0.000000  \n",
       "2                            0.991095  \n",
       "3                            0.000000  \n",
       "4                            1.057609  \n",
       "...                               ...  \n",
       "197474                       0.000000  \n",
       "197475                       0.000000  \n",
       "197476                       0.000000  \n",
       "197477                       0.411256  \n",
       "197478                       0.000000  \n",
       "\n",
       "[197479 rows x 55 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc7b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_train = cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dc35df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing 49 features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_features(df, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Normalize all numerical features per (language, sentence) group using MinMaxScaler.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing features to normalize\n",
    "        exclude_cols: List of columns to exclude from normalization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with normalized features\n",
    "    \"\"\"\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = ['language', 'sentence', 'node', 'target', 'community_id', 'n_nodes']\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Get all numeric columns to normalize\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Filter out excluded columns\n",
    "    normalize_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "    print(f\"Normalizing {len(normalize_cols)} features\")\n",
    "    \n",
    "    # Group by language and sentence, then normalize each group independently\n",
    "    for (lang, sent), group in df.groupby(['language', 'sentence']):\n",
    "        # For each group, normalize all numerical features\n",
    "        for col in normalize_cols:\n",
    "            # Skip columns with all same values (can't normalize)\n",
    "            if group[col].nunique() <= 1:\n",
    "                continue\n",
    "                \n",
    "            # Handle potential NaN values\n",
    "            if group[col].isna().any():\n",
    "                # Fill NaN with 0 before normalizing\n",
    "                group_values = group[col].fillna(0).values.reshape(-1, 1)\n",
    "            else:\n",
    "                group_values = group[col].values.reshape(-1, 1)\n",
    "                \n",
    "            # Apply MinMaxScaler\n",
    "            try:\n",
    "                scaler = MinMaxScaler()\n",
    "                normalized_values = scaler.fit_transform(group_values).flatten()\n",
    "                \n",
    "                # Update the normalized dataframe\n",
    "                indices = group.index\n",
    "                df_normalized.loc[indices, col] = normalized_values\n",
    "            except Exception as e:\n",
    "                print(f\"Error normalizing {col} for {lang}, {sent}: {e}\")\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "def batch_normalize_features(df, batch_size=100, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Normalize all numerical features in batches to handle large dataframes.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing features to normalize\n",
    "        batch_size: Number of (language, sentence) groups to process at once\n",
    "        exclude_cols: List of columns to exclude from normalization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with normalized features\n",
    "    \"\"\"\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = ['language', 'sentence', 'node', 'target', 'community_id', 'n_nodes']\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Get unique (language, sentence) combinations\n",
    "    unique_groups = df[['language', 'sentence']].drop_duplicates()\n",
    "    total_groups = len(unique_groups)\n",
    "    print(f\"Total groups to normalize: {total_groups}\")\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, total_groups, batch_size):\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(total_groups-1)//batch_size + 1}\")\n",
    "        batch_groups = unique_groups.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Create mask for the current batch\n",
    "        mask = False\n",
    "        for _, row in batch_groups.iterrows():\n",
    "            lang, sent = row['language'], row['sentence']\n",
    "            group_mask = (df['language'] == lang) & (df['sentence'] == sent)\n",
    "            mask = mask | group_mask\n",
    "        \n",
    "        # Get the subset of data for the current batch\n",
    "        batch_df = df[mask].copy()\n",
    "        \n",
    "        # Normalize the batch\n",
    "        normalized_batch = normalize_features(batch_df, exclude_cols)\n",
    "        \n",
    "        # Update the normalized dataframe\n",
    "        df_normalized.loc[mask] = normalized_batch\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "def smart_normalize_features(df):\n",
    "    \"\"\"\n",
    "    Intelligently normalize features based on their characteristics.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing features to normalize\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with normalized features\n",
    "    \"\"\"\n",
    "    # Basic columns that shouldn't be normalized\n",
    "    non_feature_cols = ['language', 'sentence', 'node', 'target', 'n_nodes', 'community_id']\n",
    "    \n",
    "    # Binary columns (0/1) shouldn't be normalized\n",
    "    binary_cols = []\n",
    "    for col in df.columns:\n",
    "        if col in non_feature_cols:\n",
    "            continue\n",
    "        if set(df[col].dropna().unique()).issubset({0, 1}):\n",
    "            binary_cols.append(col)\n",
    "    \n",
    "    print(f\"Detected {len(binary_cols)} binary columns that won't be normalized\")\n",
    "    \n",
    "    # ID or categorical columns shouldn't be normalized\n",
    "    id_cols = []\n",
    "    for col in df.columns:\n",
    "        if col in non_feature_cols or col in binary_cols:\n",
    "            continue\n",
    "        # Check if column might be categorical\n",
    "        if df[col].dtype == 'object' or (df[col].dtype.kind in 'if' and df[col].nunique() < 10):\n",
    "            id_cols.append(col)\n",
    "    \n",
    "    print(f\"Detected {len(id_cols)} potential ID/categorical columns that won't be normalized\")\n",
    "    \n",
    "    # Columns to exclude from normalization\n",
    "    exclude_cols = non_feature_cols + binary_cols + id_cols\n",
    "    \n",
    "    # Normalize the remaining features by group\n",
    "    return batch_normalize_features(df, exclude_cols=exclude_cols)\n",
    "\n",
    "# Example usage:\n",
    "# Normalize all features in the expanded training data\n",
    "# normalized_df = smart_normalize_features(expanded_train)\n",
    "\n",
    "# You can also use the original approach you provided but with all numeric features:\n",
    "def normalize_all_numeric_features(df):\n",
    "    \"\"\"\n",
    "    Normalize all numeric features using your original approach\n",
    "    \"\"\"\n",
    "    # Make a copy\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Get all numeric features (excluding the ones we don't want to normalize)\n",
    "    exclude_cols = ['language', 'sentence', 'node', 'target', 'n_nodes', 'community_id']\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    features = [col for col in numeric_cols if col not in exclude_cols]\n",
    "    \n",
    "    print(f\"Normalizing {len(features)} features\")\n",
    "    \n",
    "    # Normalize each feature per (language, sentence) group\n",
    "    df_normalized[features] = df_normalized.groupby(['language', 'sentence'])[features]\\\n",
    "        .transform(lambda x: MinMaxScaler().fit_transform(x.values.reshape(-1, 1)).flatten())\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# Choose one of these approaches:\n",
    "# normalized_df = smart_normalize_features(expanded_train_df)  # More robust, handles edge cases\n",
    "normalized_df = normalize_all_numeric_features(expanded_train)  # Similar to your original approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5027d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_train = normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120977e",
   "metadata": {},
   "source": [
    "# Create a Train - Validation Set\n",
    "\n",
    "In our dataset, each row represents a node within a graph, and each graph corresponds to a unique (language, sentence) pair. To ensure that the model evaluation is valid, we perform grouped splitting based on these identifiers.\n",
    "\n",
    "If we randomly split individual rows into training and validation sets, nodes from the same graph could appear in both sets. This introduces data leakage, allowing the model to indirectly learn about the validation data during training. As a result, performance metrics would be over-optimistic and unreliable.\n",
    "\n",
    "To prevent this, we group the data by language and sentence, ensuring that entire graphs remain in either the training or validation set, but never both. This approach preserves the structural independence of graphs across splits and results in a more realistic and fair evaluation of the model’s generalization capability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "201f4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a unique group identifier (optional but clean)\n",
    "expanded_train['group'] = expanded_train['language'].astype(str) + '_' + expanded_train['sentence'].astype(str)\n",
    "\n",
    "# Get unique groups\n",
    "unique_groups = expanded_train['group'].unique()\n",
    "\n",
    "# Split the groups\n",
    "train_groups, val_groups = train_test_split(unique_groups, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select rows by group\n",
    "train_df = expanded_train[expanded_train['group'].isin(train_groups)].reset_index(drop=True)\n",
    "val_df = expanded_train[expanded_train['group'].isin(val_groups)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cedd91c",
   "metadata": {},
   "source": [
    "## Imbalance handling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d518311",
   "metadata": {},
   "source": [
    "### Oversampling with RANDOMOVERSAMPLER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec72544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom imblearn.over_sampling import RandomOverSampler\\nimport pandas as pd\\n\\n# Step 1: Separate features and target\\nX = train_df.drop(columns=['target', 'language', 'sentence', 'node','group'])  # Only numerical features\\ny = train_df['target']\\n\\n# Save identifier columns to merge back later\\nid_cols = train_df[['language', 'sentence', 'node']].reset_index(drop=True)\\n\\n# Step 2: Apply RandomOverSampler to only the minority class (target==1)\\nros = RandomOverSampler(sampling_strategy='minority', random_state=42)\\nX_resampled, y_resampled = ros.fit_resample(X, y)\\n\\n# Step 3: Reattach metadata\\nid_resampled = id_cols.iloc[ros.sample_indices_].reset_index(drop=True)\\nresampled_df = pd.concat([id_resampled, pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='target')], axis=1)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Separate features and target\n",
    "X = train_df.drop(columns=['target', 'language', 'sentence', 'node','group'])  # Only numerical features\n",
    "y = train_df['target']\n",
    "\n",
    "# Save identifier columns to merge back later\n",
    "id_cols = train_df[['language', 'sentence', 'node']].reset_index(drop=True)\n",
    "\n",
    "# Step 2: Apply RandomOverSampler to only the minority class (target==1)\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Step 3: Reattach metadata\n",
    "id_resampled = id_cols.iloc[ros.sample_indices_].reset_index(drop=True)\n",
    "resampled_df = pd.concat([id_resampled, pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='target')], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81947f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272dead",
   "metadata": {},
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3e94",
   "metadata": {},
   "source": [
    "Will the sentences be treated as all sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45ddccc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     67\u001b[39m scoring = {\n\u001b[32m     68\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: make_scorer(accuracy_score),\n\u001b[32m     69\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m: make_scorer(precision_score, average=\u001b[33m'\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m'\u001b[39m, zero_division=\u001b[32m0\u001b[39m),\n\u001b[32m     70\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m: make_scorer(recall_score, average=\u001b[33m'\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m'\u001b[39m, zero_division=\u001b[32m0\u001b[39m),\n\u001b[32m     71\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m: make_scorer(f1_score, average=\u001b[33m'\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m'\u001b[39m, zero_division=\u001b[32m0\u001b[39m)\n\u001b[32m     72\u001b[39m }\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# === Prepare your data ===\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Ensure `resampled_df`, `val_df`, and `features` are defined beforehand.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m X_train = resampled_df[\u001b[43mfeatures\u001b[49m + [\u001b[33m'\u001b[39m\u001b[33mn_nodes\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     77\u001b[39m y_train = resampled_df[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     78\u001b[39m groups_train = resampled_df[\u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    ExtraTreesClassifier, BaggingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Define parameter grids ===\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'model__C': [0.01, 0.1, 1, 10]},\n",
    "    'Random Forest': {'model__n_estimators': [100, 200], 'model__max_depth': [None, 10, 20]},\n",
    "    'XGBoost': {\n",
    "        'model__learning_rate': [0.01, 0.05],\n",
    "        'model__n_estimators': [100, 300],\n",
    "        'model__max_depth': [4, 6],\n",
    "        'model__subsample': [0.8],\n",
    "        'model__colsample_bytree': [0.8]\n",
    "    },\n",
    "    'Decision Tree': {'model__max_depth': [None, 10, 20], 'model__min_samples_split': [2, 5, 10]},\n",
    "    'KNN': {'model__n_neighbors': [3, 5, 7], 'model__weights': ['uniform', 'distance']},\n",
    "    'Extra Trees': {'model__n_estimators': [100, 200], 'model__max_depth': [None, 10]},\n",
    "    'Gradient Boosting': {'model__n_estimators': [100, 200], 'model__learning_rate': [0.05, 0.1], 'model__max_depth': [3, 5]},\n",
    "    'AdaBoost': {'model__n_estimators': [50, 100], 'model__learning_rate': [0.5, 1.0]},\n",
    "    'Naive Bayes': {},\n",
    "    'MLP': {'model__hidden_layer_sizes': [(50,), (100,)], 'model__activation': ['relu', 'tanh'], 'model__alpha': [0.0001, 0.001]},\n",
    "    'Bagging': {'model__n_estimators': [10, 50], 'model__max_samples': [0.8, 1.0]},\n",
    "    'Calibrated SVM': CalibratedClassifierCV(estimator=SVC(probability=True, class_weight='balanced', random_state=42)),\n",
    "    'QDA': {'model__reg_param': [0.0, 0.1, 0.5]}\n",
    "}\n",
    "\n",
    "# === Define models ===\n",
    "model_classes = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'XGBoost': XGBClassifier(objective='binary:logistic', scale_pos_weight=30, subsample=0.8, colsample_bytree=0.8, random_state=42, eval_metric='logloss'),\n",
    "    'Decision Tree': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'MLP': MLPClassifier(max_iter=500, random_state=42),\n",
    "    'Bagging': BaggingClassifier(random_state=42),\n",
    "    'Calibrated SVM': {\n",
    "    'model__estimator__C': [0.1, 1],\n",
    "    'model__estimator__kernel': ['linear']\n",
    "},\n",
    "    'QDA': QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# === Scoring setup ===\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average='macro', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "# === Prepare your data ===\n",
    "# Ensure `resampled_df`, `val_df`, and `features` are defined beforehand.\n",
    "X_train = resampled_df[features + ['n_nodes']]\n",
    "y_train = resampled_df['target']\n",
    "groups_train = resampled_df['sentence']\n",
    "\n",
    "X_val = val_df[features + ['n_nodes']]\n",
    "y_val = val_df['target']\n",
    "\n",
    "# === Cross-validation setup ===\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# === Run models ===\n",
    "best_models = {}\n",
    "\n",
    "for name, base_model in model_classes.items():\n",
    "    print(f\"\\n {name}\")\n",
    "    pipe = Pipeline([('model', base_model)])\n",
    "    param_grid = param_grids[name]\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=gkf, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "    try:\n",
    "        grid.fit(X_train, y_train, groups=groups_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        best_models[name] = best_model\n",
    "\n",
    "        print(f\"   Best hyperparameters: {grid.best_params_}\")\n",
    "\n",
    "        y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "        print(\"   Validation Set Evaluation:\")\n",
    "        print(f\"    Accuracy:  {accuracy_score(y_val, y_pred_val):.4f}\")\n",
    "        print(f\"    Precision: {precision_score(y_val, y_pred_val, average='macro', zero_division=0):.4f}\")\n",
    "        print(f\"    Recall:    {recall_score(y_val, y_pred_val, average='macro', zero_division=0):.4f}\")\n",
    "        print(f\"    F1 Score:  {f1_score(y_val, y_pred_val, average='macro', zero_division=0):.4f}\")\n",
    "        print(f\"    F1 Score:  {classification_report(y_val, y_pred_val, target_names=['Non-Root', 'Root'])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Skipped {name} due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b02f9a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gkf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run separate search for Random Forest to isolate best model\u001b[39;00m\n\u001b[32m      2\u001b[39m rf_pipe = Pipeline([(\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, model_classes[\u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m])])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m rf_grid = GridSearchCV(rf_pipe, param_grids[\u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m], cv=\u001b[43mgkf\u001b[49m, scoring=\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m rf_grid.fit(X_train, y_train, groups=groups_train)\n\u001b[32m      6\u001b[39m best_rf_model = rf_grid.best_estimator_.named_steps[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# extract RandomForestClassifier from pipeline\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'gkf' is not defined"
     ]
    }
   ],
   "source": [
    "  \n",
    "# Run separate search for Random Forest to isolate best model\n",
    "rf_pipe = Pipeline([('model', model_classes['Random Forest'])])\n",
    "rf_grid = GridSearchCV(rf_pipe, param_grids['Random Forest'], cv=gkf, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "best_rf_model = rf_grid.best_estimator_.named_steps['model']  # extract RandomForestClassifier from pipeline\n",
    "\n",
    "# Get importances\n",
    "importances = best_rf_model.feature_importances_\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features + ['n_nodes'], importances)\n",
    "plt.title('Feature Importance - Best Random Forest Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3489739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_centralities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m edges = ast.literal_eval(row[\u001b[33m'\u001b[39m\u001b[33medgelist\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m T = nx.from_edgelist(edges)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m centralities = \u001b[43mcompute_centralities\u001b[49m(edges)\n\u001b[32m     10\u001b[39m test_nodes = []\n\u001b[32m     11\u001b[39m test_feats = []\n",
      "\u001b[31mNameError\u001b[39m: name 'compute_centralities' is not defined"
     ]
    }
   ],
   "source": [
    "# === Predicting for the test set using ensemble of best models ===\n",
    "submission_rows = []\n",
    "top_k = 3\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    edges = ast.literal_eval(row['edgelist'])\n",
    "    T = nx.from_edgelist(edges)\n",
    "    centralities = compute_centralities(edges)\n",
    "\n",
    "    test_nodes = []\n",
    "    test_feats = []\n",
    "    for node, feats in centralities.items():\n",
    "        test_nodes.append(node)\n",
    "        test_feats.append(feats)\n",
    "\n",
    "    test_feats_df = pd.DataFrame(test_feats, columns=features)\n",
    "    test_feats_df['n_nodes'] = row['n']\n",
    "\n",
    "    probs = np.zeros(len(test_feats_df))\n",
    "\n",
    "    # Use the trained best models from the grid search\n",
    "    for model in best_models.values():\n",
    "        probs += model.predict_proba(test_feats_df)[:, 1]\n",
    "    probs /= len(best_models)\n",
    "\n",
    "    # Select top-k nodes with the highest probabilities\n",
    "    top_indices = np.argsort(probs)[-top_k:][::-1]\n",
    "    top_roots = [test_nodes[i] for i in top_indices]\n",
    "\n",
    "    predicted_root = test_nodes[np.argmax(probs)]\n",
    "    submission_rows.append({'id': row['id'], 'root': predicted_root})\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Submission file created: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5871f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
